{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "# Initialize Pinecone with the API key and environment variables\n",
    "api_key = os.getenv(\"PINECONE_API_KEY\")\n",
    "environment = os.getenv(\"PINECONE_ENV\")\n",
    "\n",
    "# Initialize Pinecone with the updated class method\n",
    "# pc = Pinecone(api_key=\"abbaae8c-8f9e-45fe-8af9-4b3dcb590a1f\")\n",
    "# pc.environment = \"us-east-1\"\n",
    "\n",
    "# Initialize Pinecone with the environment variables\n",
    "pc = Pinecone(api_key=api_key)\n",
    "pc.environment = environment\n",
    "\n",
    "# print(\"API Key loaded successfully:\", api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define index name and dimension\n",
    "index_name = \"pinecone\"\n",
    "dimension = 18  # Use appropriate dimensions for your vectors\n",
    "\n",
    "# Check if the index exists, create it if not\n",
    "if index_name not in pc.list_indexes():\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=dimension,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\")\n",
    "    )\n",
    "else:\n",
    "    print(f\"Index '{index_name}' already exists.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to index 'pinecone' with dimension: 18\n"
     ]
    }
   ],
   "source": [
    "# Connect to the index\n",
    "index = pc.Index(index_name)\n",
    "\n",
    "# Check the dimensionality of the index\n",
    "index_info = index.describe_index_stats()\n",
    "expected_dim = index_info['dimension']\n",
    "print(f\"Connected to index '{index_name}' with dimension: {expected_dim}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting new document ID 'doc1' into the index.\n",
      "Inserting new document ID 'doc2' into the index.\n",
      "Inserting new document ID 'doc3' into the index.\n",
      "Inserting new document ID 'doc4' into the index.\n",
      "Inserting new document ID 'doc5' into the index.\n",
      "All documents have been upserted successfully.\n"
     ]
    }
   ],
   "source": [
    "# Documents to be indexed\n",
    "documents = {\n",
    "    \"doc1\": \"Machine learning is fascinating.\",\n",
    "    \"doc2\": \"Artificial intelligence is evolving rapidly.\",\n",
    "    \"doc3\": \"Deep learning improves neural networks.\",\n",
    "    \"doc4\": \"Python programming is essential in AI development.\",\n",
    "    \"doc5\": \"region of success.\"\n",
    "}\n",
    "\n",
    "# Convert documents to vectors using TF-IDF with a fixed number of features\n",
    "vectorizer = TfidfVectorizer(max_features=expected_dim)  # Adjust max_features to match the index dimension\n",
    "doc_ids = list(documents.keys())\n",
    "doc_vectors = vectorizer.fit_transform(documents.values()).toarray()\n",
    "\n",
    "# Upsert (insert or update) documents in Pinecone\n",
    "for i in range(len(doc_ids)):\n",
    "    vector = doc_vectors[i].tolist()\n",
    "    search_results = index.query(vector=vector, top_k=1, namespace=\"ns-1\")\n",
    "    if search_results['matches']:\n",
    "        print(f\"Updating document ID '{doc_ids[i]}' in the index.\")\n",
    "    else:\n",
    "        print(f\"Inserting new document ID '{doc_ids[i]}' into the index.\")\n",
    "    index.upsert(vectors=[{\"id\": doc_ids[i], \"values\": vector}], namespace=\"ns-1\")\n",
    "\n",
    "print(\"All documents have been upserted successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document ID: doc4\n",
      "Score: 0.393795\n",
      "Content: Python programming is essential in AI development.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query to search for\n",
    "query = \"AI\"\n",
    "\n",
    "# Convert query to vector\n",
    "query_vector = vectorizer.transform([query]).toarray()\n",
    "query_vector = query_vector[0].tolist()  # Convert numpy array to list\n",
    "\n",
    "# Perform search in Pinecone\n",
    "search_results = index.query(vector=query_vector, top_k=1, namespace=\"ns-1\")\n",
    "\n",
    "# Display results\n",
    "for match in search_results['matches']:\n",
    "    doc_id = match['id']\n",
    "    score = match['score']\n",
    "    content = documents.get(doc_id, \"Document content not found.\")\n",
    "    print(f\"Document ID: {doc_id}\\nScore: {score}\\nContent: {content}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 'doc4' has been updated successfully.\n"
     ]
    }
   ],
   "source": [
    "# Update content of a document\n",
    "documents[\"doc4\"] = \"Python is widely used for AI and ML development.\"\n",
    "\n",
    "# Convert updated document to vector\n",
    "updated_vector = vectorizer.transform([documents[\"doc4\"]]).toarray()\n",
    "\n",
    "# Upsert the updated document\n",
    "index.upsert(vectors=[{\"id\": \"doc4\", \"values\": updated_vector[0]}], namespace=\"ns-1\")\n",
    "print(\"Document 'doc4' has been updated successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document ID 'doc5' has been successfully deleted.\n"
     ]
    }
   ],
   "source": [
    "# Document ID to be deleted\n",
    "doc_id_to_delete = \"doc5\"\n",
    "\n",
    "# Check if the document exists in the index\n",
    "query_vector = vectorizer.transform([documents[doc_id_to_delete]]).toarray()[0].tolist()\n",
    "search_results = index.query(vector=query_vector, top_k=1, namespace=\"ns-1\")\n",
    "\n",
    "if search_results['matches']:\n",
    "    # If the document is found, proceed with deletion\n",
    "    index.delete(ids=[doc_id_to_delete], namespace=\"ns-1\")\n",
    "    print(f\"Document ID '{doc_id_to_delete}' has been successfully deleted.\")\n",
    "else:\n",
    "    print(f\"Document ID '{doc_id_to_delete}' not found in the index. No deletion performed.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
